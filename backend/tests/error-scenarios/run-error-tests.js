/**
 * Error Scenario Test Runner
 * 
 * Runs all error scenario tests and generates comprehensive reports
 */

const { execSync } = require('child_process');
const fs = require('fs');
const path = require('path');

const testSuites = [
  {
    name: 'Failure Recovery Tests',
    file: 'failure-recovery.test.ts',
    description: 'Tests for all error scenarios and recovery mechanism validation'
  },
  {
    name: 'Error Classification Tests',
    file: 'error-classification.test.ts',
    description: 'Tests for proper error classification and recovery strategy selection'
  },
  {
    name: 'Recovery Mechanisms Tests',
    file: 'recovery-mechanisms.test.ts',
    description: 'Tests for validation of recovery mechanisms and their effectiveness'
  },
  {
    name: 'Timeout Testing',
    file: 'timeout-testing.test.ts',
    description: 'Tests for hook timeout scenarios and timeout recovery'
  },
  {
    name: 'Timeout Configuration Tests',
    file: 'timeout-configuration.test.ts',
    description: 'Tests for timeout configuration management and validation'
  },
  {
    name: 'Graceful Degradation Tests',
    file: 'graceful-degradation.test.ts',
    description: 'Tests for degradation scenarios and partial failure handling'
  },
  {
    name: 'System Resilience Tests',
    file: 'system-resilience.test.ts',
    description: 'Tests for overall system resilience and stress testing'
  }
];

async function runErrorScenarioTests() {
  console.log('ðŸ§ª Running Error Scenario Tests...\n');
  
  const results = [];
  let totalTests = 0;
  let totalPassed = 0;
  let totalFailed = 0;

  for (const suite of testSuites) {
    console.log(`ðŸ“‹ Running: ${suite.name}`);
    console.log(`   ${suite.description}`);
    
    try {
      const output = execSync(
        `npx jest tests/error-scenarios/${suite.file} --verbose --json`,
        { 
          encoding: 'utf8',
          cwd: path.join(__dirname, '../..'),
          timeout: 60000 // 60 second timeout per suite
        }
      );
      
      const result = JSON.parse(output);
      const suiteResult = result.testResults[0];
      
      results.push({
        name: suite.name,
        file: suite.file,
        description: suite.description,
        status: 'passed',
        tests: suiteResult.numPassingTests,
        failures: suiteResult.numFailingTests,
        duration: suiteResult.perfStats.end - suiteResult.perfStats.start
      });
      
      totalTests += suiteResult.numPassingTests + suiteResult.numFailingTests;
      totalPassed += suiteResult.numPassingTests;
      totalFailed += suiteResult.numFailingTests;
      
      console.log(`   âœ… Passed: ${suiteResult.numPassingTests} tests`);
      if (suiteResult.numFailingTests > 0) {
        console.log(`   âŒ Failed: ${suiteResult.numFailingTests} tests`);
      }
      
    } catch (error) {
      console.log(`   âŒ Suite failed to run: ${error.message}`);
      results.push({
        name: suite.name,
        file: suite.file,
        description: suite.description,
        status: 'error',
        error: error.message,
        tests: 0,
        failures: 1,
        duration: 0
      });
      totalFailed++;
    }
    
    console.log('');
  }

  // Generate summary report
  const report = {
    timestamp: new Date().toISOString(),
    summary: {
      totalSuites: testSuites.length,
      totalTests,
      totalPassed,
      totalFailed,
      successRate: totalTests > 0 ? (totalPassed / totalTests * 100).toFixed(2) : 0
    },
    suites: results,
    requirements: {
      '1.4': 'Graceful degradation and error handling',
      '2.2': 'Clear error messages and recovery',
      '3.1': 'Performance and timeout handling',
      '8.1': 'Data integrity during failures'
    }
  };

  // Write detailed report
  const reportPath = path.join(__dirname, 'error-test-report.json');
  fs.writeFileSync(reportPath, JSON.stringify(report, null, 2));

  // Generate markdown summary
  const markdownReport = generateMarkdownReport(report);
  const markdownPath = path.join(__dirname, 'ERROR_TESTING_SUMMARY.md');
  fs.writeFileSync(markdownPath, markdownReport);

  // Print summary
  console.log('ðŸ“Š Error Scenario Testing Summary');
  console.log('================================');
  console.log(`Total Test Suites: ${report.summary.totalSuites}`);
  console.log(`Total Tests: ${report.summary.totalTests}`);
  console.log(`Passed: ${report.summary.totalPassed}`);
  console.log(`Failed: ${report.summary.totalFailed}`);
  console.log(`Success Rate: ${report.summary.successRate}%`);
  console.log('');
  console.log(`ðŸ“„ Detailed report: ${reportPath}`);
  console.log(`ðŸ“ Summary report: ${markdownPath}`);

  if (totalFailed > 0) {
    console.log('\nâŒ Some tests failed. Please review the detailed report.');
    process.exit(1);
  } else {
    console.log('\nâœ… All error scenario tests passed!');
  }
}

function generateMarkdownReport(report) {
  return `# Error Scenario Testing Summary

Generated: ${report.timestamp}

## Overview

This document summarizes the comprehensive error scenario testing for the lifecycle hooks refactoring project. These tests validate the system's ability to handle failures gracefully and maintain stability under adverse conditions.

## Test Results Summary

- **Total Test Suites**: ${report.summary.totalSuites}
- **Total Tests**: ${report.summary.totalTests}
- **Passed**: ${report.summary.totalPassed}
- **Failed**: ${report.summary.totalFailed}
- **Success Rate**: ${report.summary.successRate}%

## Requirements Coverage

${Object.entries(report.requirements).map(([req, desc]) => `- **${req}**: ${desc}`).join('\n')}

## Test Suite Details

${report.suites.map(suite => `
### ${suite.name}

**File**: \`${suite.file}\`  
**Description**: ${suite.description}  
**Status**: ${suite.status === 'passed' ? 'âœ… Passed' : 'âŒ Failed'}  
**Tests**: ${suite.tests} passed${suite.failures > 0 ? `, ${suite.failures} failed` : ''}  
**Duration**: ${suite.duration}ms  
${suite.error ? `**Error**: ${suite.error}` : ''}
`).join('\n')}

## Test Categories

### 1. Failure Recovery Tests
- Database connection failures
- Validation service failures  
- Calculation service failures
- Service integration failures
- Fallback behavior validation
- System resilience under multiple failures

### 2. Error Classification Tests
- Critical error classification
- Warning error classification
- Recovery strategy selection
- Configuration-based error handling
- Error message localization
- Error context preservation

### 3. Recovery Mechanisms Tests
- Retry mechanisms with exponential backoff
- Circuit breaker pattern implementation
- Fallback data provision
- Service isolation and recovery
- Recovery monitoring and alerting

### 4. Timeout Testing
- Hook timeout scenarios
- Timeout recovery mechanisms
- Progressive timeout increases
- Timeout circuit breaker
- Concurrent timeout handling

### 5. Timeout Configuration Tests
- Configuration loading and validation
- Dynamic configuration updates
- Environment-specific configurations
- Performance-based optimization
- Configuration monitoring and alerting

### 6. Graceful Degradation Tests
- Validation service degradation
- Calculation service degradation
- Database performance degradation
- Partial service failures
- System resilience testing

### 7. System Resilience Tests
- High concurrent request load
- Sustained load performance
- Memory and resource management
- Service isolation and fault tolerance
- Recovery and self-healing mechanisms

## Key Achievements

1. **Comprehensive Error Coverage**: All major error scenarios are tested
2. **Graceful Degradation**: System maintains functionality during failures
3. **Performance Under Load**: System handles high concurrent requests
4. **Resource Management**: Efficient memory and resource usage
5. **Service Isolation**: Failures don't cascade between services
6. **Auto-Recovery**: System can detect and recover from transient failures

## Recommendations

1. **Monitoring**: Implement comprehensive monitoring based on test insights
2. **Alerting**: Set up alerts for the error patterns identified in tests
3. **Documentation**: Update operational documentation with failure scenarios
4. **Training**: Train team on error handling patterns validated by tests

## Next Steps

1. Integrate error scenario tests into CI/CD pipeline
2. Set up automated performance regression testing
3. Implement monitoring dashboards based on test metrics
4. Create runbooks for common failure scenarios

---

*This report was generated automatically by the error scenario test runner.*
`;
}

// Run the tests if this script is executed directly
if (require.main === module) {
  runErrorScenarioTests().catch(error => {
    console.error('Error running tests:', error);
    process.exit(1);
  });
}

module.exports = { runErrorScenarioTests };